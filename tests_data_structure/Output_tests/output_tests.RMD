---
title: "Model output test"
output:
  pdf_document: default
  html_document:
    number_sections: true
    self_contained: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE,
                      cache.lazy = TRUE,
                      warn = -1)
source("output_tests_extract.R")
```


# Introduction

Currently, we're using a temporary method in order to store the model output before processing them. This method is a list which has two levels. The first level is the DoE level and the second is the Usm which contains a tibble with the variables and their values.

We wanted to know if a different storage method was more adapted to our problem. So, we have implemented a second storage method which consists in a single tibble which contains all the information for each DoE and each Usm.

There are two parts in this document. The first is a description part where we'll print the storage methods, in order to make you understand how it is store inside the differents methods.
The second part is the tests part where we first describe the functions used for extraction and their use cases. And then, the results of the extraction tests for each use case.

# Methods

Let's print the storage methods. For this example, the methods contain 2 DoE's level and 6 Usms.

## First method : List

```{r print list}
# DoE, usm_number
li <- create_list(USM_list_1996,2,6,sim_data_5)
li
```

## Second method : Tibble

```{r print tibble, warning=FALSE}
# DoE, usm_number
tb <- create_tibble(USM_list_1996,2,6,sim_data_5)
tb
```

# Tests

## Use cases

First, let us describe the use cases. There are 3 use cases : Optimization, Multi-Simulation and Analysis.
Each use case has one function matching with the storage type, so each use case has two functions, one per storage method.

Now, let's see what returns each function and how they are called.

### Optimization's use case

We're beginning with the optimization's use case.
This function returns all the values for a variable with the dates.
It takes as parameters a DoE level, a Usm name and a variable name.

```{r optimization function}

res <- tibble_get_dates_and_var_values(tb,2,"bo96iN+_2","HR_1")
res

li2 <- list_get_dates_and_var_values(li,2,"bo96iN+_2","HR_1")
li2

```

### Multi-simulations' use case

This function returns the Usms names with the variable's values.
It takes as parameters a DoE level, a variable name and a date.

```{r multisim function,warning=FALSE}

res <- tibble_get_usm_names_and_var_values(tb,2,"HR_4","1996-01-05")
res

li2 <- list_get_usm_names_and_var_values(li,2,"HR_4","1996/01/05")
li2

```

### Analysis' use case

This function returns the DoE levels and the variable's values.
It takes as parameters an Usm name, a variable name and a date.

```{r analysis function, warning=FALSE}

res <- tibble_get_DOE_and_var_values(tb,"bo96iN+_2","HR_3","1996-01-05")
res

li2 <- list_get_DOE_and_var_values(li,"bo96iN+_2","HR_3","1996/01/05")
li2

```

## Tests' environment

### Work station

The following tests have been realised on the Windows OS 64 bit version. The R memory allocated initially was 8143 bytes. For some tests, the memory was raised to 8To via the memory.limit(size=) function. The test on the Windows OS were done using an Intel Core i5-8400 CPU 2.80GHz processor and a 8Go Ram. The test on Linux OS were done using a 16 core processor, 62.7Go Ram, 134Go swap, Ubuntu 18.04.4 LTS 64bit.

### Protocole

All the tests have been realised on a R script. The R memory was cleared between tests by deleting unused variables and calling the garbage collector. Also, the only active program on the computer was RStudio, in order to prevent disturbances during the tests.

### Maximum data generated

#### List

All the structures generated below didn't need any memory boost.

#### Tibble 

First, for the optimization's use case with 20 dates, the maximum DoE level we can generate with 100 Usms is 130K but we can't process it. Instead, the maximum DoE level we can process is 120K, with a memory boost. Without, we can generate a 40K DoE level.
In the case with 289 dates and 10 Usms, the maximum DoE level generated is 50K with boost and 20K without.

Then, for the multi-simulation's use case with 5 dates, the maximum Usms we can generate with a single DoE level is 20M with memory boost and 7M500K Usms without. In the case we have 289 dates, the maximum generated is 600K Usms but we can only process 500K Usms with memory boost and without we can generate 140K Usms.

Finally, for the analysis' use case with 5 dates and 10 Usms, we can generate a 4M DoE level with boost and a 1M DoE level without. In the case we have 289 dates, the maximum level DoE generated is 50K with boost and without it is 20K.

### Functions

#### Creation

We have tested 3 creation functions for the tibble and 2 for the list.

For the tibble, the first creation function use a pre allocated tibble. The second function and the third are without pre allocation. The last one, is not build the same way as the others, the tibble is organized by usm then by DoE which is the contrary of the previous one. The third function is designed to gain memory weight and allows us to generate tibble with higher dimensions than the previous functions. The last creation function is also designed for an extraction test to be faster due to the way it is build.

As results, the third function doesn't meet our expectations, it doesn't allow us to create tibble with higher dimensions and it is not faster on the extraction tests.

For the list, the first creation function is a pre allocated function and the second is a non pre allocated function.

#### Optimization's use case

For this extraction test, we have 2 functions for the tibble. The first uses the functions of the dplyr package, while the second uses the subset function.
The second function is faster, because it have less operation to do.

#### Multi-simulation's use case

For this extraction test, we have 2 functions for the list. The first function returns a pre allocated list while the second returns a non pre allocated tibble. The second function is faster because the pre allocation takes too much time.

Moreover, the second function had 2 versions, one with a binding on the name at the end and one with the binding on the name at the beginning. The results are clear, the function with binding on the name at the beginning is faster than the other.

#### Analysis' use case

This extraction test is the same as the previous. It has 2 functions for the list. The two functions have the same specificities as the multi-simulation's use case. The results are exactly the same as the multi-simulation's use case. 

## Creation's tests

Now it is time for the instanciations' tests of each storage method. However, as the current method is only temporary and we are not sure if the second will be the one that suits us the most, the instanciations' tests are not very important at the moment. If you want some details on it, you can go on the Rmd file and delete the echo=FALSE on each chunk and generate again the document.

```{r tests creation tibble, eval=FALSE, echo=FALSE}

# below is this chunk's title on the rmd
### Tibble Creation Tests

benchmark <- microbenchmark(create_tibble(USM_list_1996,10,500,sim_data),
                            create_tibble2(USM_list_1996,10,500,sim_data),
                            create_tibble3(USM_list_1996,10,500,sim_data),
                            times = 10)

benchmark

ggplot2::autoplot(benchmark)


 benchmark
Unit: milliseconds
                                             expr          min           lq         mean       median           uq          max neval
  create_tibble(USM_list_1996, 10, 500, sim_data) 1205804.5078 1226858.2402 1697771.5727 1714676.4753 2106422.4782 2266344.2604    10
 create_tibble2(USM_list_1996, 10, 500, sim_data)     116.8153     138.8559     275.4744     172.8570     345.1159     604.2929    10
 create_tibble3(USM_list_1996, 10, 500, sim_data)     749.7182     775.1101    1084.8669     895.9864    1170.2665    1898.2863    10

# below is the caption and path to plot of the benchmark above. That line should be uncomment and be put after the chunk's end, with the right path to the benchmark_tibble_creation.png file
#![benchmark creation tibble](C:/Users/Thomas/Documents/GitHub/documentation/tests_data_structure/benchmark_tibble_creation.png)
```


```{r tests creation list,eval=FALSE,echo=FALSE}

# below is this chunk's title on the rmd
### List Creation Tests

benchmark <- microbenchmark(create_list(USM_list_1996,10,50,sim_data),
                            create_list2(USM_list_1996,10,50,sim_data),
                            times = 10)
benchmark

ggplot2::autoplot(benchmark)


```


```{r tests creation best, eval=FALSE,echo=FALSE}

# below is this chunk's title on the rmd
### Best Creation Tests

tb1 = create_tibble2(USM_list_1996,10,500,sim_data)
weights <- object.size(tb1)
li1 = create_list2(USM_list_1996,10,500,sim_data)
weights <- append(weights,object.size(li1))
tb2 = create_tibble2(USM_list_1996,100,500,sim_data)
weights <- append(weights,object.size(tb2))
li2 = create_list2(USM_list_1996,100,500,sim_data)
weights <- append(weights,object.size(li2))

plot_weight <- data.frame(Instanciation_modes = c("tb1","li1","tb2","li2"), weights = weights)

graph <- ggplot(data = plot_weight,aes(x =Instanciation_modes, y=weights)) + geom_bar(stat = "identity")
print(graph)

benchmark <- microbenchmark(tb1 = create_tibble2(USM_list_1996,10,500,sim_data),
                            li1 = create_list2(USM_list_1996,10,500,sim_data),
                            tb2 = create_tibble2(USM_list_1996,100,500,sim_data),
                            li2 = create_list2(USM_list_1996,100,500,sim_data),
                            times = 10)
benchmark

ggplot2::autoplot(benchmark)


```

## Extraction's tests

We arrive now at the most important part, the extraction's tests. In this part, we will compare the results of each storage method on each use case.

For each use case's tests, optimization, multisimulation and analysis, we have done two differents types of tests. The first one, which is called "first setup" is based on the maximum of DoE and Usms we can generate and process through the functions, on the windows OS.
The second type of test, called "second setup" consists on the tests that are usually made using the functions.

Each type of test are made with some complementary tests in order to make graphics on the functions' execution time.

### Optimization's extraction test

FOr this test, we get the dates along with variable's values that we want for a specific DoE ans USm.

#### First setup : DoE from 1 to 50K, 10 Usms and 289 Dates

Here are the results for the tests on Windows OS :

```{r opti 1 windows, echo=FALSE}
doe_samp <- c(1,10000,20000,30000,40000,50000)
load("benchmark_opti_Windows_1.RData")
df <- bench_list2df(benchmark_opti_1)

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}


time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(DoE = doe_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(DoE = doe_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(DoE,Valeurs,colour=type))+labs(y = time_unit)
```

Here are the results for the tests on Linux OS :

```{r opti Linux 1, echo=FALSE}
doe_samp <- c(1,10000,20000,30000,40000,50000)
load("benchmark_opti_Linux_1.RData")
df <- bench_list2df(benchmark_opti_1)

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}


time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(DoE = doe_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(DoE = doe_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(DoE,Valeurs,colour=type))+labs(y = time_unit)
```

As we can see, the List type clearly outperforms the Tibble type.

#### Second setup : DoE from 1 to 50K, 100 Usms and 20 Dates

Windows OS results :

```{r opti Windows 2, echo=FALSE}
doe_samp <- c(1,10000,20000,30000,40000,50000)
load("benchmark_opti_Windows_2.RData")
df <- bench_list2df(benchmark_opti_2)

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}


time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(DoE = doe_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(DoE = doe_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(DoE,Valeurs,colour=type))+labs(y = time_unit)
```


Linux OS results : 

```{r opti Linux 2, echo=FALSE}
doe_samp <- c(1,10000,20000,30000,40000,50000)
load("benchmark_opti_Linux_2.RData")
df <- bench_list2df(benchmark_opti_2)

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}


time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(DoE = doe_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(DoE = doe_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(DoE,Valeurs,colour=type))+labs(y = time_unit)
```

Once again, the List type is clearly better than the Tibble Type.

We can conlude by saying this, for the opmization's use case, the List type is clearly the most suited of the two. No matter is we use the optimization's use case's functions on the maximum we could process on windows OS way or on the usual use.

This can be explained by the fact that is the tibble function, there are more operation done than in the List function.

### Multi-simulation's extraction test

For this test, we only have a single DoE, but we want to get the Usms names along with the values of the wanted variable for a specific date.

#### First setup : 1 DoE, Usms from 100K to 500K and 289 Dates

Windows OS results :

```{r multi Windows 1, echo=FALSE}
units_name <- c("nanoseconds","microseconds","milliseconds","seconds")
units_dim <- c("ns","us","ms","s")
usm_samp <- c(100000,200000,300000,400000,500000)

load("benchmark_multi_Windows_1.RData")
load("benchmark_multi_Windows_1_list.RData")
load("benchmark_multi_Windows_1_tibble.RData")

df <- bench_list2df(benchmark_multi_1, id = "usm") 

unit_str <- df$unit[1]
com_unit <- units_dim[which(units_name == unit_str)]

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}

last_time_tb <- summary(benchmark_multi_1_tb, unit = com_unit) %>% mutate(unit = unit_str)
last_time_li <- summary(benchmark_multi_1_li, unit = com_unit) %>% mutate(unit = unit_str)

time_list <- append(time_list,last_time_li$median)
time_tb <- append(time_tb,last_time_tb$median)

time_unit <- paste('median_log10_',unit_str,sep="")

df_li<- data.frame(Usms = usm_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(Usms = usm_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_li,df_tb)
ggplot(final)+geom_line(aes(Usms,Valeurs,colour=type))+labs(y = time_unit)
```

Linux OS results :

```{r multi 1 Linux,echo=FALSE} 
usm_samp <- c(100000,200000,300000,400000,500000)
load("benchmark_multi_Linux_1.RData")
df <- bench_list2df(benchmark_multi_1, id = "usm")

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_multi_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_multi_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_multi_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_multi_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}

time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(Usms = usm_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(Usms = usm_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(Usms,Valeurs,colour=type))+labs(y = time_unit)
```


We can see that the Tibble is faster than the List in this first setup.

#### Second setup : 1 DoE, Usms from 100K to 1 Million and 5 Dates

Windows OS results :

```{r multi Windows 2, echo=FALSE}
usm_samp <- c(100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000)
load("benchmark_multi_Windows_2.RData")
df <- bench_list2df(benchmark_multi_2, id = "usm")

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_multi_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_multi_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_multi_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_multi_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}

time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(Usms = usm_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(Usms = usm_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(Usms,Valeurs,colour=type))+labs(y = time_unit)
```

Linux OS results :

```{r multi Linux 2, echo=FALSE}
usm_samp <- c(100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000)
load("benchmark_multi_Linux_2.RData")
df <- bench_list2df(benchmark_multi_2, id = "usm")

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_multi_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_multi_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_multi_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_multi_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}

time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(Usms = usm_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(Usms = usm_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(Usms,Valeurs,colour=type))+labs(y = time_unit)
```

The results on this graph follow the results on the previous one. The Tibble storage method is more adapted to the multi-simulation use case than the List.

We can explain this by the fact that there are more operation done in the List function than in the Tibble function.

### Analysis' extraction test

For this test, we get the DoE aong with the variable's values for the wanted variable for a specific Usm ans date.

#### First setup : DoE from 10K to 50K, 10 Usms and 289 Dates

Windows OS results :

```{r analysis Windows 1,echo=FALSE} 
doe_samp <- c(10000,20000,30000,40000,50000)
load("benchmark_analysis_Windows_1.RData")
df <- bench_list2df(benchmark_analysis_1)

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}

time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(DoE = doe_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(DoE = doe_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(DoE,Valeurs,colour=type))+labs(y = time_unit)
```

Linux OS results :

```{r analysis Linux 1, echo=FALSE}
doe_samp <- c(10000,20000,30000,40000,50000)
load("benchmark_analysis_Linux_1.RData")
df <- bench_list2df(benchmark_analysis_1)

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}

time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(DoE = doe_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(DoE = doe_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(DoE,Valeurs,colour=type))+labs(y = time_unit)
```

We can see that the List are faster than the Tibble on these tests.

#### Second setup : DoE from 10K to 50K, 10 Usms and 5 Dates

Windows OS results :

```{r analysis Windows 2, echo=FALSE}
doe_samp <- c(10000,20000,30000,40000,50000)
load("benchmark_analysis_Windows_2.RData")
df <- bench_list2df(benchmark_analysis_2)

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}

time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(DoE = doe_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(DoE = doe_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(DoE,Valeurs,colour=type))+labs(y = time_unit)
```

Linux OS results :

```{r analysis Linux 2, echo=FALSE}
doe_samp <- c(10000,20000,30000,40000,50000)
load("benchmark_analysis_Linux_2.RData")
df <- bench_list2df(benchmark_analysis_2)

time_list <- list()
time_tb <- list()
cpt_list = 1
cpt_tb = 1

time_df_opti_list <- dplyr::filter(df,expr == "li") %>% dplyr::select(median)
time_df_opti_tb <- dplyr::filter(df,expr == "tb") %>% dplyr::select(median)

for (time in time_df_opti_list) {
  if (cpt_list == 1) {
    time_list <- time
  }
  else {
    time_list <- append(time_list,time)
  }
  cpt_list <- cpt_list + 1
}

for (time in time_df_opti_tb) {
  if (cpt_tb == 1) {
    time_tb <- time
  }
  else {
    time_tb <- append(time_list,time)
  }
  cpt_tb <- cpt_tb + 1
}

time_unit <- paste('median_log10_',df$unit[1],sep="")

df_list <- data.frame(DoE = doe_samp,Valeurs = log10(time_list), type = "List" )
df_tb <- data.frame(DoE = doe_samp,Valeurs = log10(time_tb), type = "Tibble")
final <- rbind(df_list,df_tb)
ggplot(final)+geom_line(aes(DoE,Valeurs,colour=type))+labs(y = time_unit)
```

Unlikely to the previous results, this time it's the Tibble that is faster than the List. We maybe can explain that on the way the dplyr::filter function has been coded. Indeed, in the List function, the wanted Usms are get first, then their variables and values are processed while in the Tibble function, each tibble's row is tested. And this process takes more time when they are 289 dates per Usm than when they are only 5. We can also conclude that it is faster to search information in a tibble using the dplyr::filter function than in a List.

# Conclusion

First of all, the results we get using both OS are matching but we cannot say that they are concluant yet. The first reason is that we tested some use cases that are not very used which is the case for the optimization. This type of optimization is not the common one. The second reason is that we can see that there can be differences in results according to the number of dates you are using. Especially for the analysis case. The last reason is that we done these tests on an only one way to store the data which was by DoE by Usm but maybe there are others storage way which ca give better results or reversed results or both, that's why the results are not concluant yet but they give us some hints in the direction to follow.